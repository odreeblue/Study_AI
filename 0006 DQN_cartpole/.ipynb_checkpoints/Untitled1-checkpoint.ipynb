{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d92bfa78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (fc1): Linear(in_features=4, out_features=32, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (fc3): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n",
      "0 Episode: Finished after 12 steps : 최근 10 에피소드의 평균 단계 수 = 1.2\n",
      "1 Episode: Finished after 11 steps : 최근 10 에피소드의 평균 단계 수 = 2.3\n",
      "2 Episode: Finished after 10 steps : 최근 10 에피소드의 평균 단계 수 = 3.3\n",
      "3 Episode: Finished after 9 steps : 최근 10 에피소드의 평균 단계 수 = 4.2\n",
      "4 Episode: Finished after 10 steps : 최근 10 에피소드의 평균 단계 수 = 5.2\n",
      "5 Episode: Finished after 9 steps : 최근 10 에피소드의 평균 단계 수 = 6.1\n",
      "6 Episode: Finished after 10 steps : 최근 10 에피소드의 평균 단계 수 = 7.1\n",
      "7 Episode: Finished after 9 steps : 최근 10 에피소드의 평균 단계 수 = 8.0\n",
      "8 Episode: Finished after 12 steps : 최근 10 에피소드의 평균 단계 수 = 9.2\n",
      "9 Episode: Finished after 9 steps : 최근 10 에피소드의 평균 단계 수 = 10.1\n",
      "10 Episode: Finished after 10 steps : 최근 10 에피소드의 평균 단계 수 = 9.9\n",
      "11 Episode: Finished after 12 steps : 최근 10 에피소드의 평균 단계 수 = 10.0\n",
      "12 Episode: Finished after 9 steps : 최근 10 에피소드의 평균 단계 수 = 9.9\n",
      "13 Episode: Finished after 10 steps : 최근 10 에피소드의 평균 단계 수 = 10.0\n",
      "14 Episode: Finished after 9 steps : 최근 10 에피소드의 평균 단계 수 = 9.9\n",
      "15 Episode: Finished after 12 steps : 최근 10 에피소드의 평균 단계 수 = 10.2\n",
      "16 Episode: Finished after 11 steps : 최근 10 에피소드의 평균 단계 수 = 10.3\n",
      "17 Episode: Finished after 12 steps : 최근 10 에피소드의 평균 단계 수 = 10.6\n",
      "18 Episode: Finished after 20 steps : 최근 10 에피소드의 평균 단계 수 = 11.4\n",
      "19 Episode: Finished after 17 steps : 최근 10 에피소드의 평균 단계 수 = 12.2\n",
      "20 Episode: Finished after 16 steps : 최근 10 에피소드의 평균 단계 수 = 12.8\n",
      "21 Episode: Finished after 28 steps : 최근 10 에피소드의 평균 단계 수 = 14.4\n",
      "22 Episode: Finished after 27 steps : 최근 10 에피소드의 평균 단계 수 = 16.2\n",
      "23 Episode: Finished after 8 steps : 최근 10 에피소드의 평균 단계 수 = 16.0\n",
      "24 Episode: Finished after 11 steps : 최근 10 에피소드의 평균 단계 수 = 16.2\n",
      "25 Episode: Finished after 21 steps : 최근 10 에피소드의 평균 단계 수 = 17.1\n",
      "26 Episode: Finished after 26 steps : 최근 10 에피소드의 평균 단계 수 = 18.6\n",
      "27 Episode: Finished after 28 steps : 최근 10 에피소드의 평균 단계 수 = 20.2\n",
      "28 Episode: Finished after 21 steps : 최근 10 에피소드의 평균 단계 수 = 20.3\n",
      "29 Episode: Finished after 24 steps : 최근 10 에피소드의 평균 단계 수 = 21.0\n",
      "30 Episode: Finished after 21 steps : 최근 10 에피소드의 평균 단계 수 = 21.5\n",
      "31 Episode: Finished after 14 steps : 최근 10 에피소드의 평균 단계 수 = 20.1\n",
      "32 Episode: Finished after 12 steps : 최근 10 에피소드의 평균 단계 수 = 18.6\n",
      "33 Episode: Finished after 16 steps : 최근 10 에피소드의 평균 단계 수 = 19.4\n",
      "34 Episode: Finished after 14 steps : 최근 10 에피소드의 평균 단계 수 = 19.7\n",
      "35 Episode: Finished after 22 steps : 최근 10 에피소드의 평균 단계 수 = 19.8\n",
      "36 Episode: Finished after 13 steps : 최근 10 에피소드의 평균 단계 수 = 18.5\n",
      "37 Episode: Finished after 8 steps : 최근 10 에피소드의 평균 단계 수 = 16.5\n",
      "38 Episode: Finished after 10 steps : 최근 10 에피소드의 평균 단계 수 = 15.4\n",
      "39 Episode: Finished after 10 steps : 최근 10 에피소드의 평균 단계 수 = 14.0\n",
      "40 Episode: Finished after 10 steps : 최근 10 에피소드의 평균 단계 수 = 12.9\n",
      "41 Episode: Finished after 9 steps : 최근 10 에피소드의 평균 단계 수 = 12.4\n",
      "42 Episode: Finished after 9 steps : 최근 10 에피소드의 평균 단계 수 = 12.1\n",
      "43 Episode: Finished after 14 steps : 최근 10 에피소드의 평균 단계 수 = 11.9\n",
      "44 Episode: Finished after 10 steps : 최근 10 에피소드의 평균 단계 수 = 11.5\n",
      "45 Episode: Finished after 10 steps : 최근 10 에피소드의 평균 단계 수 = 10.3\n",
      "46 Episode: Finished after 10 steps : 최근 10 에피소드의 평균 단계 수 = 10.0\n",
      "47 Episode: Finished after 10 steps : 최근 10 에피소드의 평균 단계 수 = 10.2\n",
      "48 Episode: Finished after 9 steps : 최근 10 에피소드의 평균 단계 수 = 10.1\n",
      "49 Episode: Finished after 9 steps : 최근 10 에피소드의 평균 단계 수 = 10.0\n",
      "50 Episode: Finished after 9 steps : 최근 10 에피소드의 평균 단계 수 = 9.9\n",
      "51 Episode: Finished after 12 steps : 최근 10 에피소드의 평균 단계 수 = 10.2\n",
      "52 Episode: Finished after 14 steps : 최근 10 에피소드의 평균 단계 수 = 10.7\n",
      "53 Episode: Finished after 10 steps : 최근 10 에피소드의 평균 단계 수 = 10.3\n",
      "54 Episode: Finished after 9 steps : 최근 10 에피소드의 평균 단계 수 = 10.2\n",
      "55 Episode: Finished after 9 steps : 최근 10 에피소드의 평균 단계 수 = 10.1\n",
      "56 Episode: Finished after 13 steps : 최근 10 에피소드의 평균 단계 수 = 10.4\n",
      "57 Episode: Finished after 13 steps : 최근 10 에피소드의 평균 단계 수 = 10.7\n",
      "58 Episode: Finished after 13 steps : 최근 10 에피소드의 평균 단계 수 = 11.1\n",
      "59 Episode: Finished after 17 steps : 최근 10 에피소드의 평균 단계 수 = 11.9\n",
      "60 Episode: Finished after 18 steps : 최근 10 에피소드의 평균 단계 수 = 12.8\n",
      "61 Episode: Finished after 18 steps : 최근 10 에피소드의 평균 단계 수 = 13.4\n",
      "62 Episode: Finished after 15 steps : 최근 10 에피소드의 평균 단계 수 = 13.5\n",
      "63 Episode: Finished after 23 steps : 최근 10 에피소드의 평균 단계 수 = 14.8\n",
      "64 Episode: Finished after 25 steps : 최근 10 에피소드의 평균 단계 수 = 16.4\n",
      "65 Episode: Finished after 23 steps : 최근 10 에피소드의 평균 단계 수 = 17.8\n",
      "66 Episode: Finished after 35 steps : 최근 10 에피소드의 평균 단계 수 = 20.0\n",
      "67 Episode: Finished after 25 steps : 최근 10 에피소드의 평균 단계 수 = 21.2\n",
      "68 Episode: Finished after 20 steps : 최근 10 에피소드의 평균 단계 수 = 21.9\n",
      "69 Episode: Finished after 22 steps : 최근 10 에피소드의 평균 단계 수 = 22.4\n",
      "70 Episode: Finished after 34 steps : 최근 10 에피소드의 평균 단계 수 = 24.0\n",
      "71 Episode: Finished after 53 steps : 최근 10 에피소드의 평균 단계 수 = 27.5\n",
      "72 Episode: Finished after 33 steps : 최근 10 에피소드의 평균 단계 수 = 29.3\n",
      "73 Episode: Finished after 74 steps : 최근 10 에피소드의 평균 단계 수 = 34.4\n",
      "74 Episode: Finished after 23 steps : 최근 10 에피소드의 평균 단계 수 = 34.2\n",
      "75 Episode: Finished after 32 steps : 최근 10 에피소드의 평균 단계 수 = 35.1\n",
      "76 Episode: Finished after 36 steps : 최근 10 에피소드의 평균 단계 수 = 35.2\n",
      "77 Episode: Finished after 23 steps : 최근 10 에피소드의 평균 단계 수 = 35.0\n",
      "78 Episode: Finished after 31 steps : 최근 10 에피소드의 평균 단계 수 = 36.1\n",
      "79 Episode: Finished after 47 steps : 최근 10 에피소드의 평균 단계 수 = 38.6\n",
      "80 Episode: Finished after 38 steps : 최근 10 에피소드의 평균 단계 수 = 39.0\n",
      "81 Episode: Finished after 41 steps : 최근 10 에피소드의 평균 단계 수 = 37.8\n",
      "82 Episode: Finished after 61 steps : 최근 10 에피소드의 평균 단계 수 = 40.6\n",
      "83 Episode: Finished after 29 steps : 최근 10 에피소드의 평균 단계 수 = 36.1\n",
      "84 Episode: Finished after 23 steps : 최근 10 에피소드의 평균 단계 수 = 36.1\n",
      "85 Episode: Finished after 40 steps : 최근 10 에피소드의 평균 단계 수 = 36.9\n",
      "86 Episode: Finished after 27 steps : 최근 10 에피소드의 평균 단계 수 = 36.0\n",
      "87 Episode: Finished after 73 steps : 최근 10 에피소드의 평균 단계 수 = 41.0\n",
      "88 Episode: Finished after 29 steps : 최근 10 에피소드의 평균 단계 수 = 40.8\n",
      "89 Episode: Finished after 62 steps : 최근 10 에피소드의 평균 단계 수 = 42.3\n",
      "90 Episode: Finished after 27 steps : 최근 10 에피소드의 평균 단계 수 = 41.2\n",
      "91 Episode: Finished after 55 steps : 최근 10 에피소드의 평균 단계 수 = 42.6\n",
      "92 Episode: Finished after 32 steps : 최근 10 에피소드의 평균 단계 수 = 39.7\n",
      "93 Episode: Finished after 37 steps : 최근 10 에피소드의 평균 단계 수 = 40.5\n",
      "94 Episode: Finished after 29 steps : 최근 10 에피소드의 평균 단계 수 = 41.1\n",
      "95 Episode: Finished after 50 steps : 최근 10 에피소드의 평균 단계 수 = 42.1\n",
      "96 Episode: Finished after 59 steps : 최근 10 에피소드의 평균 단계 수 = 45.3\n",
      "97 Episode: Finished after 46 steps : 최근 10 에피소드의 평균 단계 수 = 42.6\n",
      "98 Episode: Finished after 48 steps : 최근 10 에피소드의 평균 단계 수 = 44.5\n",
      "99 Episode: Finished after 48 steps : 최근 10 에피소드의 평균 단계 수 = 43.1\n",
      "100 Episode: Finished after 44 steps : 최근 10 에피소드의 평균 단계 수 = 44.8\n",
      "101 Episode: Finished after 43 steps : 최근 10 에피소드의 평균 단계 수 = 43.6\n",
      "102 Episode: Finished after 48 steps : 최근 10 에피소드의 평균 단계 수 = 45.2\n",
      "103 Episode: Finished after 62 steps : 최근 10 에피소드의 평균 단계 수 = 47.7\n",
      "104 Episode: Finished after 33 steps : 최근 10 에피소드의 평균 단계 수 = 48.1\n",
      "105 Episode: Finished after 34 steps : 최근 10 에피소드의 평균 단계 수 = 46.5\n",
      "106 Episode: Finished after 69 steps : 최근 10 에피소드의 평균 단계 수 = 47.5\n",
      "107 Episode: Finished after 76 steps : 최근 10 에피소드의 평균 단계 수 = 50.5\n",
      "108 Episode: Finished after 103 steps : 최근 10 에피소드의 평균 단계 수 = 56.0\n",
      "109 Episode: Finished after 68 steps : 최근 10 에피소드의 평균 단계 수 = 58.0\n",
      "110 Episode: Finished after 107 steps : 최근 10 에피소드의 평균 단계 수 = 64.3\n",
      "111 Episode: Finished after 100 steps : 최근 10 에피소드의 평균 단계 수 = 70.0\n",
      "112 Episode: Finished after 86 steps : 최근 10 에피소드의 평균 단계 수 = 73.8\n",
      "113 Episode: Finished after 78 steps : 최근 10 에피소드의 평균 단계 수 = 75.4\n",
      "114 Episode: Finished after 101 steps : 최근 10 에피소드의 평균 단계 수 = 82.2\n",
      "115 Episode: Finished after 107 steps : 최근 10 에피소드의 평균 단계 수 = 89.5\n",
      "116 Episode: Finished after 90 steps : 최근 10 에피소드의 평균 단계 수 = 91.6\n",
      "117 Episode: Finished after 171 steps : 최근 10 에피소드의 평균 단계 수 = 101.1\n",
      "118 Episode: Finished after 135 steps : 최근 10 에피소드의 평균 단계 수 = 104.3\n",
      "119 Episode: Finished after 172 steps : 최근 10 에피소드의 평균 단계 수 = 114.7\n",
      "120 Episode: Finished after 134 steps : 최근 10 에피소드의 평균 단계 수 = 117.4\n",
      "121 Episode: Finished after 128 steps : 최근 10 에피소드의 평균 단계 수 = 120.2\n",
      "122 Episode: Finished after 124 steps : 최근 10 에피소드의 평균 단계 수 = 124.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 136.2\n",
      "124 Episode: Finished after 131 steps : 최근 10 에피소드의 평균 단계 수 = 139.2\n",
      "125 Episode: Finished after 123 steps : 최근 10 에피소드의 평균 단계 수 = 140.8\n",
      "126 Episode: Finished after 110 steps : 최근 10 에피소드의 평균 단계 수 = 142.8\n",
      "127 Episode: Finished after 130 steps : 최근 10 에피소드의 평균 단계 수 = 138.7\n",
      "128 Episode: Finished after 173 steps : 최근 10 에피소드의 평균 단계 수 = 142.5\n",
      "129 Episode: Finished after 113 steps : 최근 10 에피소드의 평균 단계 수 = 136.6\n",
      "130 Episode: Finished after 129 steps : 최근 10 에피소드의 평균 단계 수 = 136.1\n",
      "131 Episode: Finished after 193 steps : 최근 10 에피소드의 평균 단계 수 = 142.6\n",
      "132 Episode: Finished after 95 steps : 최근 10 에피소드의 평균 단계 수 = 139.7\n",
      "133 Episode: Finished after 99 steps : 최근 10 에피소드의 평균 단계 수 = 129.6\n",
      "134 Episode: Finished after 114 steps : 최근 10 에피소드의 평균 단계 수 = 127.9\n",
      "135 Episode: Finished after 146 steps : 최근 10 에피소드의 평균 단계 수 = 130.2\n",
      "136 Episode: Finished after 139 steps : 최근 10 에피소드의 평균 단계 수 = 133.1\n",
      "137 Episode: Finished after 130 steps : 최근 10 에피소드의 평균 단계 수 = 133.1\n",
      "138 Episode: Finished after 103 steps : 최근 10 에피소드의 평균 단계 수 = 126.1\n",
      "139 Episode: Finished after 126 steps : 최근 10 에피소드의 평균 단계 수 = 127.4\n",
      "140 Episode: Finished after 123 steps : 최근 10 에피소드의 평균 단계 수 = 126.8\n",
      "141 Episode: Finished after 104 steps : 최근 10 에피소드의 평균 단계 수 = 117.9\n",
      "142 Episode: Finished after 107 steps : 최근 10 에피소드의 평균 단계 수 = 119.1\n",
      "143 Episode: Finished after 124 steps : 최근 10 에피소드의 평균 단계 수 = 121.6\n",
      "144 Episode: Finished after 144 steps : 최근 10 에피소드의 평균 단계 수 = 124.6\n",
      "145 Episode: Finished after 126 steps : 최근 10 에피소드의 평균 단계 수 = 122.6\n",
      "146 Episode: Finished after 138 steps : 최근 10 에피소드의 평균 단계 수 = 122.5\n",
      "147 Episode: Finished after 136 steps : 최근 10 에피소드의 평균 단계 수 = 123.1\n",
      "148 Episode: Finished after 144 steps : 최근 10 에피소드의 평균 단계 수 = 127.2\n",
      "149 Episode: Finished after 170 steps : 최근 10 에피소드의 평균 단계 수 = 131.6\n",
      "150 Episode: Finished after 173 steps : 최근 10 에피소드의 평균 단계 수 = 136.6\n",
      "151 Episode: Finished after 126 steps : 최근 10 에피소드의 평균 단계 수 = 138.8\n",
      "152 Episode: Finished after 154 steps : 최근 10 에피소드의 평균 단계 수 = 143.5\n",
      "153 Episode: Finished after 115 steps : 최근 10 에피소드의 평균 단계 수 = 142.6\n",
      "154 Episode: Finished after 123 steps : 최근 10 에피소드의 평균 단계 수 = 140.5\n",
      "155 Episode: Finished after 178 steps : 최근 10 에피소드의 평균 단계 수 = 145.7\n",
      "156 Episode: Finished after 108 steps : 최근 10 에피소드의 평균 단계 수 = 142.7\n",
      "157 Episode: Finished after 163 steps : 최근 10 에피소드의 평균 단계 수 = 145.4\n",
      "158 Episode: Finished after 149 steps : 최근 10 에피소드의 평균 단계 수 = 145.9\n",
      "159 Episode: Finished after 136 steps : 최근 10 에피소드의 평균 단계 수 = 142.5\n",
      "160 Episode: Finished after 134 steps : 최근 10 에피소드의 평균 단계 수 = 138.6\n",
      "161 Episode: Finished after 141 steps : 최근 10 에피소드의 평균 단계 수 = 140.1\n",
      "162 Episode: Finished after 141 steps : 최근 10 에피소드의 평균 단계 수 = 138.8\n",
      "163 Episode: Finished after 129 steps : 최근 10 에피소드의 평균 단계 수 = 140.2\n",
      "164 Episode: Finished after 132 steps : 최근 10 에피소드의 평균 단계 수 = 141.1\n",
      "165 Episode: Finished after 152 steps : 최근 10 에피소드의 평균 단계 수 = 138.5\n",
      "166 Episode: Finished after 129 steps : 최근 10 에피소드의 평균 단계 수 = 140.6\n",
      "167 Episode: Finished after 141 steps : 최근 10 에피소드의 평균 단계 수 = 138.4\n",
      "168 Episode: Finished after 146 steps : 최근 10 에피소드의 평균 단계 수 = 138.1\n",
      "169 Episode: Finished after 153 steps : 최근 10 에피소드의 평균 단계 수 = 139.8\n",
      "170 Episode: Finished after 186 steps : 최근 10 에피소드의 평균 단계 수 = 145.0\n",
      "171 Episode: Finished after 137 steps : 최근 10 에피소드의 평균 단계 수 = 144.6\n",
      "172 Episode: Finished after 157 steps : 최근 10 에피소드의 평균 단계 수 = 146.2\n",
      "173 Episode: Finished after 172 steps : 최근 10 에피소드의 평균 단계 수 = 150.5\n",
      "174 Episode: Finished after 135 steps : 최근 10 에피소드의 평균 단계 수 = 150.8\n",
      "175 Episode: Finished after 175 steps : 최근 10 에피소드의 평균 단계 수 = 153.1\n",
      "176 Episode: Finished after 133 steps : 최근 10 에피소드의 평균 단계 수 = 153.5\n",
      "177 Episode: Finished after 155 steps : 최근 10 에피소드의 평균 단계 수 = 154.9\n",
      "178 Episode: Finished after 146 steps : 최근 10 에피소드의 평균 단계 수 = 154.9\n",
      "179 Episode: Finished after 135 steps : 최근 10 에피소드의 평균 단계 수 = 153.1\n",
      "180 Episode: Finished after 125 steps : 최근 10 에피소드의 평균 단계 수 = 147.0\n",
      "181 Episode: Finished after 143 steps : 최근 10 에피소드의 평균 단계 수 = 147.6\n",
      "182 Episode: Finished after 148 steps : 최근 10 에피소드의 평균 단계 수 = 146.7\n",
      "183 Episode: Finished after 142 steps : 최근 10 에피소드의 평균 단계 수 = 143.7\n",
      "184 Episode: Finished after 139 steps : 최근 10 에피소드의 평균 단계 수 = 144.1\n",
      "185 Episode: Finished after 139 steps : 최근 10 에피소드의 평균 단계 수 = 140.5\n",
      "186 Episode: Finished after 143 steps : 최근 10 에피소드의 평균 단계 수 = 141.5\n",
      "187 Episode: Finished after 157 steps : 최근 10 에피소드의 평균 단계 수 = 141.7\n",
      "188 Episode: Finished after 137 steps : 최근 10 에피소드의 평균 단계 수 = 140.8\n",
      "189 Episode: Finished after 148 steps : 최근 10 에피소드의 평균 단계 수 = 142.1\n",
      "190 Episode: Finished after 153 steps : 최근 10 에피소드의 평균 단계 수 = 144.9\n",
      "191 Episode: Finished after 130 steps : 최근 10 에피소드의 평균 단계 수 = 143.6\n",
      "192 Episode: Finished after 163 steps : 최근 10 에피소드의 평균 단계 수 = 145.1\n",
      "193 Episode: Finished after 134 steps : 최근 10 에피소드의 평균 단계 수 = 144.3\n",
      "194 Episode: Finished after 161 steps : 최근 10 에피소드의 평균 단계 수 = 146.5\n",
      "195 Episode: Finished after 139 steps : 최근 10 에피소드의 평균 단계 수 = 146.5\n",
      "196 Episode: Finished after 140 steps : 최근 10 에피소드의 평균 단계 수 = 146.2\n",
      "197 Episode: Finished after 139 steps : 최근 10 에피소드의 평균 단계 수 = 144.4\n",
      "198 Episode: Finished after 125 steps : 최근 10 에피소드의 평균 단계 수 = 143.2\n",
      "199 Episode: Finished after 149 steps : 최근 10 에피소드의 평균 단계 수 = 143.3\n",
      "200 Episode: Finished after 173 steps : 최근 10 에피소드의 평균 단계 수 = 145.3\n",
      "201 Episode: Finished after 136 steps : 최근 10 에피소드의 평균 단계 수 = 145.9\n",
      "202 Episode: Finished after 184 steps : 최근 10 에피소드의 평균 단계 수 = 148.0\n",
      "203 Episode: Finished after 145 steps : 최근 10 에피소드의 평균 단계 수 = 149.1\n",
      "204 Episode: Finished after 175 steps : 최근 10 에피소드의 평균 단계 수 = 150.5\n",
      "205 Episode: Finished after 172 steps : 최근 10 에피소드의 평균 단계 수 = 153.8\n",
      "206 Episode: Finished after 160 steps : 최근 10 에피소드의 평균 단계 수 = 155.8\n",
      "207 Episode: Finished after 199 steps : 최근 10 에피소드의 평균 단계 수 = 161.8\n",
      "208 Episode: Finished after 162 steps : 최근 10 에피소드의 평균 단계 수 = 165.5\n",
      "209 Episode: Finished after 160 steps : 최근 10 에피소드의 평균 단계 수 = 166.6\n",
      "210 Episode: Finished after 135 steps : 최근 10 에피소드의 평균 단계 수 = 162.8\n",
      "211 Episode: Finished after 144 steps : 최근 10 에피소드의 평균 단계 수 = 163.6\n",
      "212 Episode: Finished after 183 steps : 최근 10 에피소드의 평균 단계 수 = 163.5\n",
      "213 Episode: Finished after 190 steps : 최근 10 에피소드의 평균 단계 수 = 168.0\n",
      "214 Episode: Finished after 181 steps : 최근 10 에피소드의 평균 단계 수 = 168.6\n",
      "215 Episode: Finished after 185 steps : 최근 10 에피소드의 평균 단계 수 = 169.9\n",
      "216 Episode: Finished after 197 steps : 최근 10 에피소드의 평균 단계 수 = 173.6\n",
      "217 Episode: Finished after 161 steps : 최근 10 에피소드의 평균 단계 수 = 169.8\n",
      "218 Episode: Finished after 139 steps : 최근 10 에피소드의 평균 단계 수 = 167.5\n",
      "219 Episode: Finished after 182 steps : 최근 10 에피소드의 평균 단계 수 = 169.7\n",
      "220 Episode: Finished after 165 steps : 최근 10 에피소드의 평균 단계 수 = 172.7\n",
      "221 Episode: Finished after 137 steps : 최근 10 에피소드의 평균 단계 수 = 172.0\n",
      "222 Episode: Finished after 157 steps : 최근 10 에피소드의 평균 단계 수 = 169.4\n",
      "223 Episode: Finished after 160 steps : 최근 10 에피소드의 평균 단계 수 = 166.4\n",
      "224 Episode: Finished after 176 steps : 최근 10 에피소드의 평균 단계 수 = 165.9\n",
      "225 Episode: Finished after 158 steps : 최근 10 에피소드의 평균 단계 수 = 163.2\n",
      "226 Episode: Finished after 180 steps : 최근 10 에피소드의 평균 단계 수 = 161.5\n",
      "227 Episode: Finished after 156 steps : 최근 10 에피소드의 평균 단계 수 = 161.0\n",
      "228 Episode: Finished after 148 steps : 최근 10 에피소드의 평균 단계 수 = 161.9\n",
      "229 Episode: Finished after 143 steps : 최근 10 에피소드의 평균 단계 수 = 158.0\n",
      "230 Episode: Finished after 177 steps : 최근 10 에피소드의 평균 단계 수 = 159.2\n",
      "231 Episode: Finished after 149 steps : 최근 10 에피소드의 평균 단계 수 = 160.4\n",
      "232 Episode: Finished after 142 steps : 최근 10 에피소드의 평균 단계 수 = 158.9\n",
      "233 Episode: Finished after 170 steps : 최근 10 에피소드의 평균 단계 수 = 159.9\n",
      "234 Episode: Finished after 189 steps : 최근 10 에피소드의 평균 단계 수 = 161.2\n",
      "235 Episode: Finished after 172 steps : 최근 10 에피소드의 평균 단계 수 = 162.6\n",
      "236 Episode: Finished after 150 steps : 최근 10 에피소드의 평균 단계 수 = 159.6\n",
      "237 Episode: Finished after 170 steps : 최근 10 에피소드의 평균 단계 수 = 161.0\n",
      "238 Episode: Finished after 157 steps : 최근 10 에피소드의 평균 단계 수 = 161.9\n",
      "239 Episode: Finished after 143 steps : 최근 10 에피소드의 평균 단계 수 = 161.9\n",
      "240 Episode: Finished after 150 steps : 최근 10 에피소드의 평균 단계 수 = 159.2\n",
      "241 Episode: Finished after 138 steps : 최근 10 에피소드의 평균 단계 수 = 158.1\n",
      "242 Episode: Finished after 156 steps : 최근 10 에피소드의 평균 단계 수 = 159.5\n",
      "243 Episode: Finished after 182 steps : 최근 10 에피소드의 평균 단계 수 = 160.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244 Episode: Finished after 160 steps : 최근 10 에피소드의 평균 단계 수 = 157.8\n",
      "245 Episode: Finished after 189 steps : 최근 10 에피소드의 평균 단계 수 = 159.5\n",
      "246 Episode: Finished after 140 steps : 최근 10 에피소드의 평균 단계 수 = 158.5\n",
      "247 Episode: Finished after 159 steps : 최근 10 에피소드의 평균 단계 수 = 157.4\n",
      "248 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 161.7\n",
      "249 Episode: Finished after 145 steps : 최근 10 에피소드의 평균 단계 수 = 161.9\n",
      "250 Episode: Finished after 185 steps : 최근 10 에피소드의 평균 단계 수 = 165.4\n",
      "251 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 171.6\n",
      "252 Episode: Finished after 154 steps : 최근 10 에피소드의 평균 단계 수 = 171.4\n",
      "253 Episode: Finished after 179 steps : 최근 10 에피소드의 평균 단계 수 = 171.1\n",
      "254 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 175.1\n",
      "255 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 176.2\n",
      "256 Episode: Finished after 157 steps : 최근 10 에피소드의 평균 단계 수 = 177.9\n",
      "257 Episode: Finished after 177 steps : 최근 10 에피소드의 평균 단계 수 = 179.7\n",
      "258 Episode: Finished after 196 steps : 최근 10 에피소드의 평균 단계 수 = 179.3\n",
      "259 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 184.8\n",
      "260 Episode: Finished after 149 steps : 최근 10 에피소드의 평균 단계 수 = 181.2\n",
      "261 Episode: Finished after 180 steps : 최근 10 에피소드의 평균 단계 수 = 179.2\n",
      "262 Episode: Finished after 175 steps : 최근 10 에피소드의 평균 단계 수 = 181.3\n",
      "263 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 183.4\n",
      "264 Episode: Finished after 180 steps : 최근 10 에피소드의 평균 단계 수 = 181.4\n",
      "265 Episode: Finished after 146 steps : 최근 10 에피소드의 평균 단계 수 = 176.0\n",
      "266 Episode: Finished after 165 steps : 최근 10 에피소드의 평균 단계 수 = 176.8\n",
      "267 Episode: Finished after 157 steps : 최근 10 에피소드의 평균 단계 수 = 174.8\n",
      "268 Episode: Finished after 190 steps : 최근 10 에피소드의 평균 단계 수 = 174.2\n",
      "269 Episode: Finished after 154 steps : 최근 10 에피소드의 평균 단계 수 = 169.6\n",
      "270 Episode: Finished after 138 steps : 최근 10 에피소드의 평균 단계 수 = 168.5\n",
      "271 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 170.5\n",
      "272 Episode: Finished after 185 steps : 최근 10 에피소드의 평균 단계 수 = 171.5\n",
      "273 Episode: Finished after 193 steps : 최근 10 에피소드의 평균 단계 수 = 170.8\n",
      "274 Episode: Finished after 157 steps : 최근 10 에피소드의 평균 단계 수 = 168.5\n",
      "275 Episode: Finished after 167 steps : 최근 10 에피소드의 평균 단계 수 = 170.6\n",
      "276 Episode: Finished after 172 steps : 최근 10 에피소드의 평균 단계 수 = 171.3\n",
      "277 Episode: Finished after 152 steps : 최근 10 에피소드의 평균 단계 수 = 170.8\n",
      "278 Episode: Finished after 169 steps : 최근 10 에피소드의 평균 단계 수 = 168.7\n",
      "279 Episode: Finished after 159 steps : 최근 10 에피소드의 평균 단계 수 = 169.2\n",
      "280 Episode: Finished after 193 steps : 최근 10 에피소드의 평균 단계 수 = 174.7\n",
      "281 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 174.7\n",
      "282 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 176.2\n",
      "283 Episode: Finished after 162 steps : 최근 10 에피소드의 평균 단계 수 = 173.1\n",
      "284 Episode: Finished after 164 steps : 최근 10 에피소드의 평균 단계 수 = 173.8\n",
      "285 Episode: Finished after 175 steps : 최근 10 에피소드의 평균 단계 수 = 174.6\n",
      "286 Episode: Finished after 149 steps : 최근 10 에피소드의 평균 단계 수 = 172.3\n",
      "287 Episode: Finished after 157 steps : 최근 10 에피소드의 평균 단계 수 = 172.8\n",
      "288 Episode: Finished after 188 steps : 최근 10 에피소드의 평균 단계 수 = 174.7\n",
      "289 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 178.8\n",
      "290 Episode: Finished after 153 steps : 최근 10 에피소드의 평균 단계 수 = 174.8\n",
      "291 Episode: Finished after 141 steps : 최근 10 에피소드의 평균 단계 수 = 168.9\n",
      "292 Episode: Finished after 180 steps : 최근 10 에피소드의 평균 단계 수 = 166.9\n",
      "293 Episode: Finished after 158 steps : 최근 10 에피소드의 평균 단계 수 = 166.5\n",
      "294 Episode: Finished after 166 steps : 최근 10 에피소드의 평균 단계 수 = 166.7\n",
      "295 Episode: Finished after 155 steps : 최근 10 에피소드의 평균 단계 수 = 164.7\n",
      "296 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 169.8\n",
      "297 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 174.1\n",
      "298 Episode: Finished after 186 steps : 최근 10 에피소드의 평균 단계 수 = 173.9\n",
      "299 Episode: Finished after 152 steps : 최근 10 에피소드의 평균 단계 수 = 169.1\n",
      "300 Episode: Finished after 168 steps : 최근 10 에피소드의 평균 단계 수 = 170.6\n",
      "301 Episode: Finished after 198 steps : 최근 10 에피소드의 평균 단계 수 = 176.3\n",
      "302 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 178.3\n",
      "303 Episode: Finished after 155 steps : 최근 10 에피소드의 평균 단계 수 = 178.0\n",
      "304 Episode: Finished after 171 steps : 최근 10 에피소드의 평균 단계 수 = 178.5\n",
      "305 Episode: Finished after 182 steps : 최근 10 에피소드의 평균 단계 수 = 181.2\n",
      "306 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 181.2\n",
      "307 Episode: Finished after 163 steps : 최근 10 에피소드의 평균 단계 수 = 177.5\n",
      "308 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 178.9\n",
      "309 Episode: Finished after 175 steps : 최근 10 에피소드의 평균 단계 수 = 181.2\n",
      "310 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 184.4\n",
      "311 Episode: Finished after 158 steps : 최근 10 에피소드의 평균 단계 수 = 180.4\n",
      "312 Episode: Finished after 150 steps : 최근 10 에피소드의 평균 단계 수 = 175.4\n",
      "313 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 179.9\n",
      "314 Episode: Finished after 165 steps : 최근 10 에피소드의 평균 단계 수 = 179.3\n",
      "315 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 181.1\n",
      "316 Episode: Finished after 189 steps : 최근 10 에피소드의 평균 단계 수 = 180.0\n",
      "317 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 183.7\n",
      "318 Episode: Finished after 153 steps : 최근 10 에피소드의 평균 단계 수 = 179.0\n",
      "319 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 181.5\n",
      "320 Episode: Finished after 154 steps : 최근 10 에피소드의 평균 단계 수 = 176.9\n",
      "321 Episode: Finished after 163 steps : 최근 10 에피소드의 평균 단계 수 = 177.4\n",
      "322 Episode: Finished after 152 steps : 최근 10 에피소드의 평균 단계 수 = 177.6\n",
      "323 Episode: Finished after 166 steps : 최근 10 에피소드의 평균 단계 수 = 174.2\n",
      "324 Episode: Finished after 168 steps : 최근 10 에피소드의 평균 단계 수 = 174.5\n",
      "325 Episode: Finished after 158 steps : 최근 10 에피소드의 평균 단계 수 = 170.3\n",
      "326 Episode: Finished after 146 steps : 최근 10 에피소드의 평균 단계 수 = 166.0\n",
      "327 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 166.0\n",
      "328 Episode: Finished after 193 steps : 최근 10 에피소드의 평균 단계 수 = 170.0\n",
      "329 Episode: Finished after 181 steps : 최근 10 에피소드의 평균 단계 수 = 168.1\n",
      "330 Episode: Finished after 154 steps : 최근 10 에피소드의 평균 단계 수 = 168.1\n",
      "331 Episode: Finished after 165 steps : 최근 10 에피소드의 평균 단계 수 = 168.3\n",
      "332 Episode: Finished after 166 steps : 최근 10 에피소드의 평균 단계 수 = 169.7\n",
      "333 Episode: Finished after 180 steps : 최근 10 에피소드의 평균 단계 수 = 171.1\n",
      "334 Episode: Finished after 165 steps : 최근 10 에피소드의 평균 단계 수 = 170.8\n",
      "335 Episode: Finished after 182 steps : 최근 10 에피소드의 평균 단계 수 = 173.2\n",
      "336 Episode: Finished after 174 steps : 최근 10 에피소드의 평균 단계 수 = 176.0\n",
      "337 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 176.0\n",
      "338 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 176.7\n",
      "339 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 178.6\n",
      "340 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 183.2\n",
      "341 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 186.7\n",
      "342 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 190.1\n",
      "343 Episode: Finished after 185 steps : 최근 10 에피소드의 평균 단계 수 = 190.6\n",
      "344 Episode: Finished after 158 steps : 최근 10 에피소드의 평균 단계 수 = 189.9\n",
      "345 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 191.7\n",
      "346 Episode: Finished after 161 steps : 최근 10 에피소드의 평균 단계 수 = 190.4\n",
      "347 Episode: Finished after 169 steps : 최근 10 에피소드의 평균 단계 수 = 187.3\n",
      "348 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 187.3\n",
      "349 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 187.3\n",
      "350 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 187.3\n",
      "351 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 187.3\n",
      "352 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 187.3\n",
      "353 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 188.8\n",
      "354 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 193.0\n",
      "355 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 193.0\n",
      "356 Episode: Finished after 178 steps : 최근 10 에피소드의 평균 단계 수 = 194.7\n",
      "357 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 197.8\n",
      "358 Episode: Finished after 163 steps : 최근 10 에피소드의 평균 단계 수 = 194.1\n",
      "359 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 194.1\n",
      "360 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 194.1\n",
      "361 Episode: Finished after 162 steps : 최근 10 에피소드의 평균 단계 수 = 190.3\n",
      "362 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 190.3\n",
      "363 Episode: Finished after 174 steps : 최근 10 에피소드의 평균 단계 수 = 187.7\n",
      "364 Episode: Finished after 188 steps : 최근 10 에피소드의 평균 단계 수 = 186.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 186.5\n",
      "366 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 188.7\n",
      "367 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 188.7\n",
      "368 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 192.4\n",
      "369 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 192.4\n",
      "370 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 192.4\n",
      "371 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 196.2\n",
      "372 Episode: Finished after 160 steps : 최근 10 에피소드의 평균 단계 수 = 192.2\n",
      "373 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 194.8\n",
      "374 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 196.0\n",
      "375 Episode: Finished after 194 steps : 최근 10 에피소드의 평균 단계 수 = 195.4\n",
      "376 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 195.4\n",
      "377 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 195.4\n",
      "378 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 195.4\n",
      "379 Episode: Finished after 187 steps : 최근 10 에피소드의 평균 단계 수 = 194.1\n",
      "380 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 194.1\n",
      "381 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 194.1\n",
      "382 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 198.1\n",
      "383 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 198.1\n",
      "384 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 198.1\n",
      "385 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 198.7\n",
      "386 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 198.7\n",
      "387 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 198.7\n",
      "388 Episode: Finished after 181 steps : 최근 10 에피소드의 평균 단계 수 = 196.8\n",
      "389 Episode: Finished after 183 steps : 최근 10 에피소드의 평균 단계 수 = 196.4\n",
      "390 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 196.4\n",
      "391 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 196.4\n",
      "392 Episode: Finished after 162 steps : 최근 10 에피소드의 평균 단계 수 = 192.6\n",
      "393 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 192.6\n",
      "394 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 192.6\n",
      "395 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 192.6\n",
      "396 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 192.6\n",
      "397 Episode: Finished after 188 steps : 최근 10 에피소드의 평균 단계 수 = 191.4\n",
      "398 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 193.3\n",
      "399 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 195.0\n",
      "400 Episode: Finished after 171 steps : 최근 10 에피소드의 평균 단계 수 = 192.1\n",
      "401 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 192.1\n",
      "402 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 195.9\n",
      "403 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 195.9\n",
      "404 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 195.9\n",
      "405 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 195.9\n",
      "406 Episode: Finished after 179 steps : 최근 10 에피소드의 평균 단계 수 = 193.8\n",
      "407 Episode: Finished after 176 steps : 최근 10 에피소드의 평균 단계 수 = 192.6\n",
      "408 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 192.6\n",
      "409 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 192.6\n",
      "410 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 195.5\n",
      "411 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 195.5\n",
      "412 Episode: Finished after 197 steps : 최근 10 에피소드의 평균 단계 수 = 195.2\n",
      "413 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 195.2\n",
      "414 Episode: Finished after 142 steps : 최근 10 에피소드의 평균 단계 수 = 189.4\n",
      "415 Episode: Finished after 175 steps : 최근 10 에피소드의 평균 단계 수 = 186.9\n",
      "416 Episode: Finished after 147 steps : 최근 10 에피소드의 평균 단계 수 = 183.7\n",
      "417 Episode: Finished after 165 steps : 최근 10 에피소드의 평균 단계 수 = 182.6\n",
      "418 Episode: Finished after 192 steps : 최근 10 에피소드의 평균 단계 수 = 181.8\n",
      "419 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 181.8\n",
      "420 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 181.8\n",
      "421 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 181.8\n",
      "422 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 182.1\n",
      "423 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 182.1\n",
      "424 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 187.9\n",
      "425 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 190.4\n",
      "426 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 195.7\n",
      "427 Episode: Finished after 162 steps : 최근 10 에피소드의 평균 단계 수 = 195.4\n",
      "428 Episode: Finished after 118 steps : 최근 10 에피소드의 평균 단계 수 = 188.0\n",
      "429 Episode: Finished after 130 steps : 최근 10 에피소드의 평균 단계 수 = 181.0\n",
      "430 Episode: Finished after 151 steps : 최근 10 에피소드의 평균 단계 수 = 176.1\n",
      "431 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 176.1\n",
      "432 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 176.1\n",
      "433 Episode: Finished after 175 steps : 최근 10 에피소드의 평균 단계 수 = 173.6\n",
      "434 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 173.6\n",
      "435 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 173.6\n",
      "436 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 173.6\n",
      "437 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 177.4\n",
      "438 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 185.6\n",
      "439 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 192.6\n",
      "440 Episode: Finished after 188 steps : 최근 10 에피소드의 평균 단계 수 = 196.3\n",
      "441 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 196.3\n",
      "442 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 196.3\n",
      "443 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 198.8\n",
      "444 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 198.8\n",
      "445 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 198.8\n",
      "446 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 198.8\n",
      "447 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 198.8\n",
      "448 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 198.8\n",
      "449 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 198.8\n",
      "450 Episode: Finished after 200 steps : 최근 10 에피소드의 평균 단계 수 = 200.0\n",
      "10에피소드 연속 성공\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n",
      "C:\\Users\\CY-Kim\\anaconda3\\envs\\neural\\lib\\site-packages\\JSAnimation\\html_writer.py:282: MatplotlibDeprecationWarning: \n",
      "The 'clear_temp' parameter of setup() was deprecated in Matplotlib 3.3 and will be removed two minor releases later. If any parameter follows 'clear_temp', they should be passed as keyword, not positionally.\n",
      "  frame_prefix, clear_temp=False)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'HTMLWriter' object has no attribute '_temp_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-801590158a25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[1;31m# 실행 엔트리 포인트\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[0mcartpole_env\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEnvironment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m \u001b[0mcartpole_env\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-801590158a25>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m                                 \u001b[1;32mif\u001b[0m \u001b[0mepisode_final\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m                                         \u001b[1;31m#애니메이션 생성 및 저장\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m                                         \u001b[0mdisplay_frames_as_gif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m                                         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m                                 \u001b[1;31m# 10 에피소드를 연속으로 195단계를 버티면 태스크 성공\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-801590158a25>\u001b[0m in \u001b[0;36mdisplay_frames_as_gif\u001b[1;34m(frames)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0manim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manimation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFuncAnimation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgcf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manimate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0manim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'movie_cartpole.gif'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# The part where i save the animation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdisplay_animation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'loop'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# 2. 이 코드에서는 namedtuple을 사용함\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\neural\\lib\\site-packages\\JSAnimation\\IPython_display.py\u001b[0m in \u001b[0;36mdisplay_animation\u001b[1;34m(anim, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;34m\"\"\"Display the animation with an IPython HTML object\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHTML\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mHTML\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manim_to_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\neural\\lib\\site-packages\\JSAnimation\\IPython_display.py\u001b[0m in \u001b[0;36manim_to_html\u001b[1;34m(anim, fps, embed_frames, default_mode)\u001b[0m\n\u001b[0;32m     74\u001b[0m             anim.save(f.name,  writer=HTMLWriter(fps=fps,\n\u001b[0;32m     75\u001b[0m                                                  \u001b[0membed_frames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0membed_frames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                                                  default_mode=default_mode))\n\u001b[0m\u001b[0;32m     77\u001b[0m             \u001b[0mhtml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\neural\\lib\\site-packages\\matplotlib\\animation.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filename, writer, fps, dpi, codec, bitrate, extra_args, metadata, extra_anim, savefig_kwargs, progress_callback)\u001b[0m\n\u001b[0;32m   1159\u001b[0m                         \u001b[0mprogress_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe_number\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_frames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m                         \u001b[0mframe_number\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m                 \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrab_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0msavefig_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\neural\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\neural\\lib\\site-packages\\matplotlib\\animation.py\u001b[0m in \u001b[0;36msaving\u001b[1;34m(self, fig, outfile, dpi, *args, **kwargs)\u001b[0m\n\u001b[0;32m    251\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\neural\\lib\\site-packages\\matplotlib\\animation.py\u001b[0m in \u001b[0;36mfinish\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    516\u001b[0m         \u001b[1;31m# Call run here now that all frame grabbing is done. All temp files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[1;31m# are available to be assembled.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    519\u001b[0m         \u001b[0mMovieWriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Will call clean-up\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\neural\\lib\\site-packages\\JSAnimation\\html_writer.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[0mof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mJS_INCLUDE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m             of.write(DISPLAY_TEMPLATE.format(id=self.new_id(),\n\u001b[1;32m--> 323\u001b[1;33m                                              \u001b[0mNframes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_temp_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m                                              \u001b[0mfill_frames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_frames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m                                              \u001b[0minterval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'HTMLWriter' object has no attribute '_temp_names'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "\n",
    "# 1. 애니메이션을 만들기\n",
    "from JSAnimation.IPython_display import display_animation\n",
    "from matplotlib import animation\n",
    "from IPython.display import display\n",
    "def display_frames_as_gif(frames):\n",
    "    \"\"\"\n",
    "    Displays a list of frames as a gif , with controls\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(frames[0].shape[1]/72.0, frames[0].shape[0]/72.0), dpi=72)\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "\n",
    "    def animate(i):\n",
    "        patch.set_data(frames[i])\n",
    "\n",
    "    anim = animation.FuncAnimation(plt.gcf(), animate, frames=len(frames), interval=50)\n",
    "    anim.save('movie_cartpole.gif') # The part where i save the animation\n",
    "    display(display_animation(anim, default_mode = 'loop'))\n",
    "\n",
    "# 2. 이 코드에서는 namedtuple을 사용함\n",
    "# named tuple을 사용하면 키-값 쌍 형태로 값을 저장할 수 있음\n",
    "# 그리고 키를 필드명으로 값에 접근 할 수 있어 편리함\n",
    "from collections import namedtuple\n",
    "#Tr = namedtuple('tr', ('name_a', 'value_b'))\n",
    "#Tr_object = Tr('이름A',100) # 출력 : tr(name_a='이름A', value_b=100)\n",
    "#print(Tr_object.name_a)  # 출력 : 100\n",
    "#print(Tr_object.name_a)  # 출력 : 이름A\n",
    "Transition = namedtuple('Transition',('state','action','next_state','reward'))\n",
    "\n",
    "# 3. 상수 정의\n",
    "ENV = 'CartPole-v0' # 태스크 이름\n",
    "GAMMA  = 0.99 # 시간 할인율\n",
    "MAX_STEPS =200 #  1에피소드 당 최대 단계 수\n",
    "NUM_EPISODES = 500 # 최대 에피소드 수\n",
    "\n",
    "# 4. Transition을 저장하기 위한 메모리 클래스\n",
    "class ReplayMemory:\n",
    "        def __init__(self, CAPACITY): # 생성자\n",
    "                self.capacity = CAPACITY # 메모리의 최대 저장 건수 ex. 10000\n",
    "                self.memory = [] #실제 Transition을 저장할 변수\n",
    "                self.index = 0 # 저장 위치를 가르칠 인덱스 변수\n",
    "        def push(self, state, action, state_next, reward):\n",
    "                '''transition = (state, action, state_next, reward)을 메모리에 저장'''\n",
    "                if len(self.memory) < self.capacity: # ex ) 100개 < 10000개 일 때\n",
    "                        self.memory.append(None) # 메모리가 가득 차지 않은 경우, memory 마지막에 None을 추가함\n",
    "                        \n",
    "                # Transition이라는 namedtuple을 사용해 키-값 쌍의 형태로 값을 저장\n",
    "                self.memory[self.index] = Transition(state, action, state_next, reward)\n",
    "\n",
    "                # 다음 저장할 위치를 한 자리 뒤로 수정\n",
    "                self.index = (self.index+1) % self.capacity # %연산자(나머지), 1/10000 = 1, 2/10000 = 2\n",
    "                \n",
    "        def sample(self, batch_size):\n",
    "                ''' batch_size 개수 만큼 무작위로 저장된 transition을 추출'''\n",
    "                return random.sample(self.memory, batch_size)\n",
    "        \n",
    "        def __len__(self):\n",
    "                '''len 함수로 현재 저장된 transition 개수를 반환'''\n",
    "                return len(self.memory)\n",
    "\n",
    "# 5. 에이전트의 두뇌 역할을 하는 클랫, DQN을 실제 수행함 ###\n",
    "# Q 함수를 딥러닝 신경망 형태로 정의\n",
    "import random \n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "CAPACITY = 10000\n",
    "\n",
    "class Brain:\n",
    "        def __init__(self, num_states, num_actions):\n",
    "                self.num_actions = num_actions # 행동의 가짓수 (오른쪽, 왼쪽)을 구함\n",
    "                \n",
    "                #transition을 기억하기 위한 메모리 객체 생성\n",
    "                self.memory = ReplayMemory(CAPACITY)\n",
    "                \n",
    "                ###신경망 구성\n",
    "                self.model = nn.Sequential()\n",
    "\n",
    "                self.model.add_module('fc1',nn.Linear(num_states, 32)) # 4 X 32 matrix\n",
    "                self.model.add_module('relu1', nn.ReLU()) # 4 X 32 matrix에 ReLU 함수\n",
    "\n",
    "                self.model.add_module('fc2',nn.Linear(32, 32)) # 32 X 32 matrix\n",
    "                self.model.add_module('relu2',nn.ReLU()) # 32 X 32 marix에 ReLU 함수\n",
    "\n",
    "                self.model.add_module('fc3',nn.Linear(32, num_actions)) # 32 X 2 matrix -> 출력 2개\n",
    "                print(self.model) # 신경망 구조 출력\n",
    "\n",
    "                ###최적화 기법 선택\n",
    "                self.optimizer = optim.Adam(self.model.parameters(), lr = 0.0001)\n",
    "        \n",
    "        def replay(self):\n",
    "                \"\"\"Experience Replay'로 신경망의 결합 가중치 학습\"\"\"\n",
    "                #----------------------------------------------------\n",
    "                # 1. 저장된 transition 수 확인\n",
    "                #----------------------------------------------------\n",
    "                # 1.1 저장된 transition의 수가 미니배치 크기보다 작으면 아무것도 하지 않음\n",
    "                if len(self.memory) < BATCH_SIZE:\n",
    "                        return\n",
    "\n",
    "                #----------------------------------------------------\n",
    "                # 2 미니 배치 생성\n",
    "                #----------------------------------------------------\n",
    "                # 2.1 메모리 객체에서 미니배치를 추출\n",
    "                transitions = self.memory.sample(BATCH_SIZE)\n",
    "\n",
    "                # 2.2 메모리 객체에서 미니배치를 추출\n",
    "                # transitions는 각 단계 별로 (state, action, state_next, reward) 형태로 BATCH_SIZE 개수만큼 저장됨\n",
    "                # 다시 말해 (state, action, state_next, reward) * BATCH_SIZE 형태가 된다\n",
    "                # 이를 미니배치로 만들기 위해\n",
    "                # (state * BATCH_SIZE, action * BATCH_SIZE, state_next * BATCH_SIZE, reward * BATCH_SIZE) 형태로 변환함\n",
    "                batch = Transition(*zip(*transitions))# Transition = namedtuple 임\n",
    "                # ex. [[1,2,3,4],[1,2,3,4],[1,2,3,4]] --> Transition(state=(1, 1, 1), action=(2, 2, 2), next_state=(3, 3, 3), reward=(4, 4, 4))\n",
    "\n",
    "                # 2.3 각 변수의 요소를 미니배치에 맞게 변형하고, 신경망으로 다룰 수 있게 Variable로 만든다\n",
    "                # state로 예를 들면, [torch.FloatTensor of size 1*4] 형태의 요소가 BATCH_SIZE 개수만큼 있는 형태임\n",
    "                # 이를 torch.FloatTensor of size BATCH_SIZE * 4 형태로 변형한다\n",
    "                # 상태, 행동, 보상, non_final 상태로 된 미니배치를 나타내는 Variable을 생성\n",
    "                # cat은 Concatenates(연접)을 의미함\n",
    "                \n",
    "                state_batch = torch.cat(batch.state)\n",
    "                action_batch = torch.cat(batch.action)\n",
    "                #print(\"action_batch  :\",action_batch)\n",
    "                reward_batch = torch.cat(batch.reward)\n",
    "                non_final_next_states = torch.cat([s for s in batch.next_state if s is not None])#batch.next_state를 하나씩 s로 꺼내서\n",
    "                                                                                                 #s가 None이 아닌거만 List로 모아라\n",
    "                \n",
    "                #----------------------------------------------------\n",
    "                # 3 정답신호로 사용할 Q(s_t, a_t)를 계산  \n",
    "                #----------------------------------------------------\n",
    "                # 3.1 신경망을 추론 모드로 전환\n",
    "                self.model.eval()# 신경망 업데이트 안됨\n",
    "\n",
    "                # 3.2 신경망으로 Q(s_t,a_t)를 계산\n",
    "                # self.model(state_batch)은 왼쪽, 오른쪽에 대한 Q값을 출력하며 [torch.FloatTensor of size BATCH_SIZE x 2] 형태\n",
    "                # 여기서부터는 실행한 행동 a_t에 대한 Q값을 계산하므로 action_batch에서 취한 행동 a_t가 왼쪽이냐, 오른쪽이냐에\n",
    "                # 대한 인덱스를 구하고, 이에 대한 Q값을 gater 메서드로 모아온다\n",
    "                #print(\"self.model(state_batch): \", self.model(state_batch))\n",
    "                state_action_values = self.model(state_batch).gather(1,action_batch)\n",
    "                #print(\"self.model(state_batch).gather(1,action_batch): \",self.model(state_batch).gather(1,action_batch))\n",
    "\n",
    "                # 3.3 max{Q(s_t+1, a)} 값을 계산한다. 이 때 다음 상태가 존재하는지 주의해야 한다.\n",
    "\n",
    "                # cartpole이 done 상태가 아니고, next_state가 존재하는지 확인하는 인덱스마스크를 만듬\n",
    "                non_final_mask = torch.BoolTensor(tuple(map(lambda s: s is not None, batch.next_state)))\n",
    "                #print(\"non_final_mask  :\", non_final_mask)\n",
    "\n",
    "                # 먼저 전체를 0으로 초기화\n",
    "                next_state_values = torch.zeros(BATCH_SIZE)\n",
    "\n",
    "                # 다음상태가 있는 인덱스에 대한 최대 Q값을 구한다\n",
    "                # 출력에 접근해서 열방향 최댓값(max(1))이 되는 [값, 인덱스]를 구한다\n",
    "                # 이 Q값(인덱스=0)을 출력한 다음 detach 메서드로 이 값을 꺼내온다\n",
    "                next_state_values[non_final_mask] = self.model(non_final_next_states).max(1)[0].detach()\n",
    "\n",
    "                # 3.4 정답 신호로 사용할 Q(s_t, a_t)값을 Q러닝 식으로 계산한다\n",
    "                expected_state_action_values = reward_batch + GAMMA * next_state_values\n",
    "\n",
    "                #----------------------------------------------------\n",
    "                # 4 결합 가중치 수정\n",
    "                #----------------------------------------------------\n",
    "                # 4.1 신경망을 학습 모드로 전환\n",
    "                self.model.train()\n",
    "\n",
    "                # 4.2 손실함수를 계산(smooth_l1_loss는 Huber 함수)\n",
    "                # expected_state_action_values는 size가 [minibatch]이므로 unsqueeze해서 [minibatch*1]로 만든다\n",
    "                loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "                # 4.3 결합 가중치를 수정한다\n",
    "                self.optimizer.zero_grad() # 경사를 초기화\n",
    "                loss.backward() #역전파 계산\n",
    "                self.optimizer.step() # 결합 가중치 수정\n",
    "        \n",
    "        def decide_action(self, state, episode):\n",
    "                '''현재 상태에 따라 행동을 결정한다'''\n",
    "                # e-greedy 알고리즘에서 서서히 최적행동의 비중을 늘린다\n",
    "                epsilon = 0.5 * (1/ (episode+1))\n",
    "\n",
    "                if epsilon <= np.random.uniform(0,1):\n",
    "                        self.model.eval() # 신경망을 추론모드로 전환\n",
    "                        with torch.no_grad():\n",
    "                                action = self.model(state).max(1)[1].view(1,1)\n",
    "                        # 신경망 출력의 최대값에 대한 인덱스 = max(1)[1]\n",
    "                        # .view(1,1)은 [torch.LongTensor of size 1]을 size 1*1로 변환하는 역할\n",
    "                else :\n",
    "                        # 행동을 무작위로 반환(0 혹은 1)\n",
    "                        action = torch.LongTensor([[random.randrange(self.num_actions)]])#행동을 무작위로 반환(0 OR 1 OR 2 OR 3)\n",
    "                        # action은 [torch.LongTensor of size 1*1]형태가 된다\n",
    "                return action\n",
    "\n",
    "class Agent:\n",
    "        def __init__(self, num_states, num_actions):\n",
    "                '''태스크의 상태 및 행동의 가짓수를 설정'''\n",
    "                self.brain = Brain(num_states, num_actions) #Agent's brain role in determining behavior\n",
    "\n",
    "        def update_Q_function(self):\n",
    "                '''Modifying the Q function'''\n",
    "                #self.brain.update_Q_table(observation, action, reward, observation_next)\n",
    "                self.brain.replay()\n",
    "\n",
    "        def get_action(self, state, episode):\n",
    "                '''Action Determination'''\n",
    "                #action = self.brain.decide_action(observation, step) \n",
    "                action = self.brain.decide_action(state, episode) \n",
    "                return action                \n",
    "        def memorize(self, state, action, state_next, reward):\n",
    "                '''메모리 객체에 state, action, state_next, reward 내용을 저장'''\n",
    "                self.brain.memory.push(state, action, state_next, reward)\n",
    "\n",
    "class Environment:\n",
    "        def __init__(self):\n",
    "                self.env = gym.make(ENV) #태스크 설정\n",
    "                num_states = self.env.observation_space.shape[0] # 태스크의 상태 변수 수(4)를 받아옴\n",
    "                num_actions = self.env.action_space.n # 태스크의 행동 가짓수(2)를 받아옴\n",
    "                self.agent = Agent(num_states, num_actions) # 에이전트 역할을 할 객체를 생성\n",
    "        \n",
    "        def run(self):\n",
    "                '''실행'''\n",
    "                episode_10_list = np.zeros(10) # 최근 10 에피소드 동안 버틴 단계수를 저장함 --> 평균 산출용\n",
    "                complete_episodes = 0 #현재까지 195단계를 버틴 에피소드 수\n",
    "                episode_final = False # 마지막 에피소드 여부\n",
    "                frames = [] # 애니메이션을 만들기 위해 마지막 에피소드의 프레임을 저장할 배열\n",
    "\n",
    "                for episode in range(NUM_EPISODES): #최대 에피소드 수만큼 반복\n",
    "                        observation = self.env.reset() # 환경 초기화\n",
    "                        state = observation # 관측을 변환없이 그대로 상태 s로 사용\n",
    "                        state = torch.from_numpy(state).type(torch.FloatTensor) # Numpy변수를 파이토치 텐서로 변환\n",
    "                        state = torch.unsqueeze(state, 0)# size 4를 size 1*4 로 변환\n",
    "\n",
    "                        for step in range(MAX_STEPS): # 1에피소드에 해당하는 반복문\n",
    "                                if episode_final is True : #마지막 에피소드에서는 각 시각의 이미지를 frames에 저장\n",
    "                                        frames.append(self.env.render(mode='rgb_array'))\n",
    "                                action = self.agent.get_action(state, episode) # 다음 행동을 결정\n",
    "\n",
    "                                # 행동 a_t를 실행해 다음 상태 s_t+1 과 done 플래그 값을 결정\n",
    "                                # action에 .item()을 호출해 행동 내용을 구함\n",
    "                                observation_next,_,done,_ = self.env.step(action.item()) #reward와 info는 사용하지 않음 _처리\n",
    "                                \n",
    "                                #보상을 부여하고 episode의 종료 판정 및 state_next를 설정\n",
    "                                if done: # 단계수가 200을 넘었거나 봉이 일정각도 이상 기울면 done이 True가 됨\n",
    "                                        state_next = None #다음 상태가 없으므로 None 으로 설정\n",
    "\n",
    "                                        #최근 10episode에서 버틴 단계수를 리스트에 저장\n",
    "                                        episode_10_list = np.hstack((episode_10_list[1:], step+1))\n",
    "                                        \n",
    "                                        if step<195:\n",
    "                                                reward = torch.FloatTensor([-1.0]) # 도중 봉이 쓰러졌다면 패널티로 -1 부여\n",
    "                                                complete_episodes = 0 # 연속 성공 에피소드 기록을 초기화\n",
    "                                        else:\n",
    "                                                reward = torch.FloatTensor([1.0]) # 봉이 서있는 채로 에피소드 마치면 1 부여\n",
    "                                                complete_episodes = complete_episodes + 1 # 연속 성공 에피소드 기록을 갱신\n",
    "                                else :\n",
    "                                        reward = torch.FloatTensor([0.0]) # 그 외의 경우는 보상 0을 부여\n",
    "                                        state_next = observation_next # 관측 결과를 그대로 상태로 사용\n",
    "                                        state_next = torch.from_numpy(state_next).type(torch.FloatTensor) # numpy->torch tensor\n",
    "                                        state_next = torch.unsqueeze(state_next, 0)#size 4를 size 1*4로 변환\n",
    "                                \n",
    "                                # 메모리에 경험을 저장\n",
    "                                self.agent.memorize(state,action,state_next, reward)\n",
    "                                # Experience Replay로 Q함수를 수정\n",
    "                                self.agent.update_Q_function()\n",
    "                                # 관측 결과를 업데이트\n",
    "                                state = state_next\n",
    "                                # 에피소드 종료 처리\n",
    "                                if done:\n",
    "                                        print('%d Episode: Finished after %d steps : 최근 10 에피소드의 평균 단계 수 = %.1f' % \n",
    "                                                                                                        (episode, step+1, episode_10_list.mean()))\n",
    "                                        break\n",
    "\n",
    "                                if episode_final is True:\n",
    "                                        #애니메이션 생성 및 저장\n",
    "                                        display_frames_as_gif(frames)\n",
    "                                        break\n",
    "                                # 10 에피소드를 연속으로 195단계를 버티면 태스크 성공\n",
    "                                if complete_episodes >=10:\n",
    "                                        print('10에피소드 연속 성공')\n",
    "                                        episode_final = True # 다음 에피소드에서 애니메이션을 생성\n",
    "\n",
    "# 실행 엔트리 포인트\n",
    "cartpole_env = Environment()\n",
    "cartpole_env.run()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c723ad1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
